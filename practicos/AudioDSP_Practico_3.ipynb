{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9R66vy-1Fn5C"
   },
   "source": [
    "\n",
    "### <center>Procesamiento Digital de Señales de Audio</center>\n",
    "#### <center>Instituto de Ingeniería Eléctrica - UdelaR</center>\n",
    "# Hoja de Ejercicios 3 - Curso 2022\n",
    "## Análisis de Fourier de tiempo corto\n",
    "### Procesamiento tiempo-frecuencia\n",
    "\n",
    "\n",
    "## Pautas para el práctico\n",
    " - La realización del presente trabajo es individual.\n",
    " - Se espera la entrega de un PDF escrito en $\\LaTeX$ o similar. El mismo tendrá:\n",
    "     - Máximo de 12 páginas\n",
    "     - Máximo de 2500 palabras\n",
    " - También se espera la entrega del código escrito, en scripts Python o en este mismo Jupyter Notebook.\n",
    " - La corrección del práctico se hará sobre lo entregado en el PDF, pero podremos apoyarnos en el razonamiento y comprensión demostrado en el código escrito. Recomendamos escribir el código de forma prolija para facilitar la comprensión presente y futura tanto de nosotros como de ustedes mismxs.\n",
    " - Los ejercicios marcados como $\\blacklozenge$ son opcionales.\n",
    "\n",
    "\n",
    "**Nombre de el/la estudiante:** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Como correr este notebook\n",
    "\n",
    "Es posible descargarlo y correrlo localmente en su computadora\n",
    "\n",
    "Tambien pueden correrlo en Google Colab usando el siguiente link.\n",
    "\n",
    "<table align=\"center\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/mrocamora/audio-dsp/blob/main/practicos/AudioDSP_Practico_2.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Correr en Google Colab</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MdUJ8uyXij2V",
    "outputId": "1c5412a9-358e-4f40-8660-8ccf67d64b40",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Al correr esta celda, se podrá acceder a archivos\n",
    "# y carpetas en su cuenta de google drive.\n",
    "# Puede ver la estructura de carpetas apretando en\n",
    "# el icono de carpeta de la barra lateral izquierda.\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 61
    },
    "id": "E1Yd4l1_GJR4",
    "outputId": "464ab4b6-c236-4f29-b870-cbc4017e3b63"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import io, signal\n",
    "from scipy.io.wavfile import read\n",
    "from IPython.display import Audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 1\n",
    "\n",
    "En este ejercicio se estudia la relación entre la transformada de Fourier de tiempo corto y la función de autocorrelación de tiempo corto. Si definimos la densidad espectral de potencia en tiempo corto de una señal ($x[n]$) en función de su transformada de Fourier en tiempo corto como\n",
    "\n",
    "\\begin{equation*}\n",
    "\tS_n(e^{jw}) = |X_n(e^{jw})|^2\n",
    "\\end{equation*}\n",
    "\n",
    "y la función de autocorrelación de tiempo corto de la señal \\(x[n]\\) como\n",
    "\n",
    "\\begin{equation*}\n",
    "\tR_n[k] = \\sum_{m=-\\infty}^{\\infty}w[n-m]x[m]w[n-k-m]x[m+k],\n",
    "\\end{equation*}\n",
    "\n",
    "probar que si\n",
    "\n",
    "\\begin{equation*}\n",
    "\tX_n(e^{jw}) = \\sum_{m=-\\infty}^{\\infty}x[m]w[n-m]e^{-jwm}\n",
    "\\end{equation*}\n",
    "\n",
    "$R_n[k]$ y $S_n(e^{jw})$ son un par de transformadas, i.e.\\ $S_n(e^{jw})$ es la transformada de Fourier de $R_n[k]$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 2\n",
    "\n",
    "En este ejercicio se estudia un método de detección de frecuencia fundamental (o _pitch_) basado en la transformada de Fourier de tiempo corto. Se sugiere utilizar el archivo _LP-mem-6-a.wav_ para probarlo.\n",
    "\n",
    "## Parte 1\n",
    "El producto armónico espectral -Harmonic Product Spectrum, HPS- (ver _Pitch Detection in the Spectral Domain, pág. 623_, en  L. R. Rabiner and R. W. Schafer, _Theory and Applications of Digital Speech Processing_. Prentice Hall, 1st ed., 2011 [1]) está dado por\n",
    "\n",
    "\\begin{equation*}\n",
    "\tP_n(e^{jw}) = \\prod_{r=1}^{K}|X_n(e^{jwr})|^2\n",
    "\\end{equation*}\n",
    "\n",
    "Tomando el logaritmo se obtiene (log-Harmonic Product Spectrum, log-HPS),\n",
    "\n",
    "\\begin{equation*}\n",
    "\t\\hat{P}_n(e^{jw}) = 2\\sum_{r=1}^{K}\\log|X_n(e^{jwr})|\n",
    "\\end{equation*}\n",
    "\n",
    "Explique por qué el HPS puede usarse para detección de _pitch_. Asuma que la señal de audio es monofónica (una única fuente armónica). ¿Qué ventajas presenta el uso del log-HPS frente al HPS? ¿Qué ocurre con señales cuya frecuencia fundamental está ausente (e.g. filtrado pasa-altos por el canal de comunicación)?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 2\n",
    "\n",
    "El espectro logarítmico acumulado (ó GLogS por sus siglas en inglés), se calcula como el promedio de logaritmo de la magnitud del espectro en posiciones armónicas de una frecuencia fundamental $f_0$, como\n",
    "\n",
    "\\begin{equation*}\n",
    "\t\\rho_n(f_0) = \\frac{1}{n_H}\\sum_{i=1}^{n_H}\\log|X_n(if_0)|\n",
    "\\end{equation*}\n",
    "\n",
    "siendo $n_H$ la cantidad de armónicos de $f_0$ cuya frecuencia es menor a cierta frecuencia máxima $f_{\\max}$.\n",
    "\n",
    "Implemente un algoritmo de detección de _pitch_ que calcule el GLogS para valores de $f_0$ distribuidos de forma logarítmica entre $55Hz$ (A1) y $1046.5Hz$ (C6) con un paso de cuarto de tono, y $f_{\\max} =  10000Hz$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 3\n",
    "\n",
    "Utilice el GLogS para obtener una representación tiempo-$f_0$, que denominaremos $f_0$-grama. Compare dicha representación con el espectrograma. Represente la frecuencia fundamental detectada y la frecuencia de referencia en el $f_0$-grama, para el archivo _LP-mem-6-a.wav_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 3\n",
    "\n",
    "En este ejercicio se implementa la técnica de phase-vocoder y se la utiliza para generar transformaciones de la señal de audio. Se sugiere utilizar el archivo _singing\\_voice.wav_ para probarla.\n",
    "\n",
    "En la etapa de análisis se calcula la transformada de Fourier de tiempo corto, como \n",
    "\n",
    "\\begin{equation*}\n",
    "    X_{n_a^u}(e^{j\\omega_k})=\\sum_{m=-\\infty}^{\\infty}w_a[n_a^u-m]\\, x[m]\\, e^{-j\\omega_kn}\n",
    "\\end{equation*}\n",
    "\n",
    "en donde, $w_a[n]$ es la ventana de análisis, $\\omega_k=\\frac{2\\pi}{N} k$, con \\(N\\) la cantidad de puntos de la DFT, y $n_a^u = u \\, R_a$, con $R_a$ el hop de análisis en muestras y $u$ el índice de la trama temporal, de valor inicial 0.\n",
    "\n",
    "En la etapa de síntesis se reconstruye la señal en el dominio del tiempo mediante la antitransformada de Fourier de cada trama temporal y el procedimiento de solapamiento y suma (overlap-add), como \n",
    "\n",
    "\\begin{equation*}\n",
    "    y[n]=\\sum_{u=-\\infty}^{\\infty}w_s[n-n_s^u]y_u[n-n_s^u]\n",
    "\\end{equation*}\n",
    "\n",
    "con\n",
    "\n",
    "\\begin{equation*}\n",
    "    y_u[n]=\\frac{1}{N}\\sum_{k=0}^{N-1}Y_{n_s^u}(e^{j\\omega_k}) \\, e^{j\\omega_kn}\n",
    "\\end{equation*}\n",
    "\n",
    "en donde, $w_s[n]$ es la ventana de síntesis, y $n_s^u=u \\, R_s$, siendo $R_s$ el hop de síntesis en muestras. Notar que $y_u[n]$ es la transformada inversa de Fourier de una trama de la STFT. Cuando no hay modificaciones entre la etapa de análisis y síntesis, $Y_{n_s^u}(e^{j\\omega_k}) = X_{n_a^u}(e^{j\\omega_k})$ y $R_s = R_a$. En ese caso la ventana de síntesis $w_s[n]$ es opcional, pero se hace importante si se aplican modificaciones, por ejemplo cuando $R_s \\neq R_a$.  \n",
    "  \n",
    "## Parte 1\n",
    "\n",
    "Implemente el análisis y la síntesis para $Y_{n_s^u}(e^{j\\omega_k})=X_{n_a^u}(e^{j\\omega_k})$ y $R_s=R_a$. Elija un valor de $R_a$ para tener reconstrucción perfecta con ventana de Hann y verifique experimentalmente. Justifique su elección."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 2\n",
    "\n",
    "Realice modificaciones de la escala temporal usando $R_s \\neq R_a$. En particular pruebe duplicando y reduciendo a la mitad la duración original. Analice los resultados obtenidos y los artefactos que se introducen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 3\n",
    "\n",
    "Para evitar la mayoría de los problemas introducidos debido a la inconsistencia de fase, se sugiere utilizar el procedimiento de desdoblamiento de fase (phase unwrapping). \n",
    "\n",
    "Asumiendo que existe un solo componente sinusoidal por bin de la DFT, podemos plantear las siguientes ecuaciones para estimar la fase de $Y_{n_s^u}(e^{j\\omega_k})$, cuando transformamos la escala temporal utilizando un hop de síntesis $R_s \\neq R_a$. \n",
    "\n",
    "Se calcula el incremento de fase heterodino, a partir del incremento de fase de tramas sucesivas \n",
    "\n",
    "\\begin{equation*}\n",
    "    \\Delta\\Phi_k^u=\\angle X_{n_a^u}(e^{j\\omega_k}) - \\angle X_{n_a^{u-1}}(e^{j\\omega_k}) - R_a \\, \\omega_k\n",
    "\\end{equation*}\n",
    "\n",
    "Notar que el término $R_a\\ \\omega_k$ es el incremento de fase que cabría esperar si la frecuencia del componente sinusoidal correspondiera exactamente a la frecuencia de análisis. \n",
    "\n",
    "Se toma el argumento principal de $\\Delta\\Phi_k^u$ entre ($-\\pi, \\pi$), que denominamos $\\Delta_p\\Phi_k^u$. \n",
    "\n",
    "Luego se calcula la estimación de la frecuencia instantánea\n",
    "\n",
    "\\begin{equation*}\n",
    "    \\hat{\\omega}_k[{n^u_a}] = \\omega_k + \\frac{1}{R_a} \\, \\Delta_p\\Phi_k^u\n",
    "\\end{equation*}\n",
    "\n",
    "Finalmente se calcula la fase de $Y_{n_s^u}(e^{j\\omega_k})$ utilizando la fórmula de propagación de fase\n",
    "\n",
    "\\begin{equation*}\n",
    "    \\angle Y_{n_s^u}(e^{j\\omega_k}) = \\angle Y_{n_s^{u-1}}(e^{j\\omega_k}) + R_s \\, \\hat{\\omega}_k[{n^u_a}]\n",
    "\\end{equation*}\n",
    "\n",
    "Notar que de acuerdo a la fórmula anterior se hace necesario acumular la fase de tramas sucesivas y establecer un valor para la fase inicial (se sugiere considerar $\\angle Y_{n_s^{0}}(e^{j\\omega_k}) = \\angle X_{n_a^{0}}(e^{j\\omega_k})$). Cabe señalar que es importante aplicar una ventana de suavizado $w_s[n]$ en la síntesis. Se sugiere utilizar ventanas de Hann con $w_a[n] = w_s[n]$. Tenga en cuenta que esto modifica el factor de escalamiento temporal. Para profundizar en el estudio de este procedimiento y otras consideraciones sobre la fase se recomienda [2,3].\n",
    "\n",
    "\n",
    "Implemente el desdoblamiento de fase y compare los resultados con los obtenidos en la parte anterior. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 4\n",
    "\n",
    "Usando el phase-vocoder implemente las siguientes transformaciones de la señal de audio. Incluya en el informe los espectrogramas de las señales generadas y entregue también las señales de audio.\n",
    "\n",
    " - %**Escalamiento temporal (\\textit{time-stretching})**: Si se reconstruye la señal de audio con un paso entre ventanas mayor al utilizado para obtener el espectrograma complejo, se obtendrá una señal más lenta que la original, y si se utiliza un paso entre ventanas menor, se obtiene una señal más rápida. ¿Se ve modificado el contenido espectral de la señal?\n",
    " - **Transposición en frecuencia (pitch-shifting)**: Se desea una señal de la misma duración que la señal original, pero alterando su contenido espectral. Para ello deben realizarse dos acciones complementarias: un escalamiento en el tiempo y un cambio en la frecuencia de muestreo. Por ejemplo, si se desea subir/bajar el contenido espectral de la señal un semitono, se debe aumentar/disminuir la duración de la señal por un factor de $2^{\\frac{1}{12}}$, y luego aumentar/disminuir la frecuencia de muestreo por el mismo factor, de modo de obtener una señal de la misma duración que la original.\n",
    " - %$\\blacklozenge$ **Voz robótica**: Para generar este efecto, se debe reconstruir la señal con el mismo paso entre ventanas que el utilizado para obtener el espectrograma complejo, pero descartando la información de fase (utilizando fase cero). Analizando este resultado, ¿es importante la información de fase para la reconstrucción de la señal?\n",
    " - $\\blacklozenge$ **Armonizador**: Utilizando el efecto de transposición en frecuencia sumar a la señal original una versión desplazada una quinta (factor de $2^{\\frac{7}{12}}\\simeq\\frac{3}{2}$).\n",
    " - $\\blacklozenge$ **Coro (_chorus_)**: Consiste en simular que la señal de voz de un único interprete es entonada por varias voces cantando al unísono (es una variación del efecto de armonización). Se deben superponer varias señales con pequeñas modificaciones de _pitch_ respecto al de la señal original y ligeramente distinto para cada uno. El cambio no debe ser mayor que un cuarto de semitono (factor de $2^{\\frac{1}{48}}$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Referencias\n",
    "\n",
    "[1] L. R. Rabiner and R. W. Schafer, *Theory and Applications of Digital Speech Processing*. Prentice\n",
    "Hall, 1st ed., 2011.\n",
    "\n",
    "[2] J. Laroche and M. Dolson, “Improved phase vocoder time-scale modification of audio,” *IEEE Transac-\n",
    "tions on Speech and Audio processing*, vol. 7, no. 3, pp. 323–332, 1999.\n",
    "\n",
    "[3] A. Gotzen, N. Bernardin, and D. Arfib., “Traditional implementations of a phase-vocoder: The tricks\n",
    "of the trade,” in *International Conference on Digital Audio Effects, Italy*, Dec. 2000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "%\\section*{Ejercicio 4}\n",
    "% Pitch detection using filter bank (Rabiner ej 6.14).\n",
    "% Queda comentado para una futura versión del práctico.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "AudioDSP - Practico 3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
